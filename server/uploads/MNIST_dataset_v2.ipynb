{"cells":[{"cell_type":"markdown","metadata":{"id":"09ZYscF9nFLC"},"source":["# Image Recognition\n","In this notebook, you will create a densely neural network to classify images in MNIST dataset."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"wP0a9UIVnBWU","executionInfo":{"status":"ok","timestamp":1735856342843,"user_tz":480,"elapsed":11803,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[],"source":["# Import TensorFlow and Keras to create the neural network\n","import tensorflow as tf\n","import tensorflow as tf\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras import backend as K\n","import numpy as np\n","\n","# Matplotlib to plot info to show the results\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"sN0CYaPpo_LO"},"source":["# Preparing the Data\n","\n","Keras has code that will load a basic version of your data into lists in Python, but they still need to be formatted to allow the neural network to use them. Reshaping and processing data into a format the neural network can consume is critical in any machine learning problem.\n","\n","In this lesson, you'll learn how to prepare the MNIST dataset so that it can be put into a neural network. There are some things you should know about the MNIST dataset."]},{"cell_type":"markdown","metadata":{"id":"nWpRhgJlBy9t"},"source":["## Minimum and Maximum Values\n","To get started, you'll create a function that analyzes the data in an array format. The function will fetch an image at the array's current index, i, from the dataset, calculate the minimum and maximum pixel values, and display them. This information will be used to preprocess the data or images and their pixels."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"M3n3zsd-9crr","executionInfo":{"status":"ok","timestamp":1735856348552,"user_tz":480,"elapsed":123,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[],"source":["# Load the MNIST Data\n","def show_min_max(array, i):\n","    random_image = array[i]\n","    print(\"min and max value in image: \", random_image.min(), random_image.max())"]},{"cell_type":"markdown","metadata":{"id":"nCGrHZfQswcJ"},"source":["## Image & Digit Label\n","Now, you'll create a function that takes an image at the array's current index i, plots the image, and displays the corresponding digit label. This function visualizes the data so the model can better evaluate and draw conclusions."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"e22svQw9_DCo","executionInfo":{"status":"ok","timestamp":1735856350357,"user_tz":480,"elapsed":122,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[],"source":["# Create a function that will plot a image from the dataset and display the digit label.\n","def plot_image(array, i, labels):\n","    plt.imshow(np.squeeze(array[i]))\n","    plt.title(\" Digit \" + str(labels[i]))\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"AelduA5as2dZ"},"source":["## Image Size & Classes\n","Next, you'll define the size for all images and the number of classes representing each label, 0-9."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"w8At-Ixr_qgF","executionInfo":{"status":"ok","timestamp":1735856352758,"user_tz":480,"elapsed":127,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[],"source":["# Create variables for the image row and column to keep track of your image size.\n","img_rows, img_cols = 28, 28\n","\n","# Create a variable called num_classes and set the value to 10 output classes.\n","num_classes = 10"]},{"cell_type":"markdown","metadata":{"id":"06wa8J9GtPUb"},"source":["## Load the Data\n","Now that you've set up the helper functions and the variables, you'll load the data to train the model and test its accuracy. In addition, you'll also print the shape of the training and test image datasets."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"b1cuJIMCAFKy","outputId":"1d9a7964-b792-4e0a-d102-15b981029223","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735856354732,"user_tz":480,"elapsed":1132,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","(60000, 28, 28)\n","(10000, 28, 28)\n"]}],"source":["# Load the data to train and test the model, as well as the labels to test the data against.\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# Load a backup copy of the untouched data, while the first copy will be processing the data and manipulating it.\n","(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data()\n","\n","# Print the shape of the training image dataset.\n","print(train_images.shape)\n","\n","# Print the shape of the test image dataset.\n","print(test_images.shape)"]},{"cell_type":"markdown","metadata":{"id":"D_mXbfPzCgT1"},"source":["# Sorting through the Data\n","\n","Data can be formatted in many different ways. However, since the MNIST data is already so well prepared for machine learning applications, there's only a little reshaping or preparation that needs to go into it.\n","\n","However, in other situations, you might come across data that needs more hefty reshaping and re-organizing. This is an important skill to develop, and as you expand your machine-learning abilities, you'll learn more about how to deal with different types of data."]},{"cell_type":"markdown","metadata":{"id":"f_6skqF0CqIA"},"source":["## Data Formatting\n","For now, you will reshape the data to be an appropriate size for your network."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8s6JxeSsCubo","executionInfo":{"status":"ok","timestamp":1735856356489,"user_tz":480,"elapsed":121,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[],"source":["# Reshape the training data by converting the list of pixels into a 28x28 grid.\n","train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n","\n","# Reshape the test data by converting the list of pixels into a 28x28 grid.\n","test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n","\n","# Create an input_shape variable to keep track of the data's shape.\n","input_shape = (img_rows, img_cols, 1)"]},{"cell_type":"markdown","metadata":{"id":"P_MKaRnDDawM"},"source":["## Data Cleaning\n","Now that the data is in the correct format, you'll do some simple data cleaning. The color in pixels is stored as an integer value between 0 and 255. While your network can learn from this information, replacing these values with a decimal between 0 and 1 will be easier. This keeps the numbers the network is dealing with small.\n","\n","This will be done by changing the data to a **float32**, a 32-bit decimal number, and then dividing it to get the 0-1 values you want."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8H4dgrfTDfBt","outputId":"f14cbf68-546d-4808-cf95-03492d45820a","colab":{"base_uri":"https://localhost:8080/","height":874},"executionInfo":{"status":"ok","timestamp":1735856358537,"user_tz":480,"elapsed":421,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["min and max value in image:  0 255\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["min and max value in image:  0.0 1.0\n"]}],"source":["# Call the plot_image function to print out the 100th image in train_images.\n","plot_image(train_images, 100, train_labels)\n","\n","# Call the show_min_max function to print the min and max values of the image.\n","show_min_max(train_images, 100)\n","\n","# Change the image values to between 0 and 1, convert that training data into float32.\n","train_images = train_images.astype('float32')\n","\n","# Change the image values to between 0 and 1, convert that test data into float32.\n","test_images = test_images.astype('float32')\n","\n","# Divide the images by 255 to make sure that each pixel is stored as a value between 0 and 1.\n","train_images /= 255\n","test_images /= 255\n","\n","# Call the plot_image function to print out the 100th image in train_images.\n","plot_image(train_images, 100, train_labels)\n","\n","# Call the show_min_max function to print the min and max values of the image.\n","show_min_max(train_images, 100)"]},{"cell_type":"markdown","metadata":{"id":"ZsHlE17nGl4L"},"source":["## One-Hot Encoding\n","MNIST is a set of hand-drawn images of the numbers 0-9. The label for each image is then simply the number 0-9.\n","\n","However, this isn't the best solution. Due to how neural networks function, they intuitively believe that the image labeled \"1\" is more similar to the image labeled \"0\" or \"2\" than the image labeled \"7\". If you write 0, 1, 2, and 7 on a sheet of paper, 1 and 7 are more similar in structure, with a long straight line, than the curves in 0 or 2.\n","\n","**One-Hot Encoding** is a technique that helps solve this problem by replacing the label on each image with a representation that the network won't think is ordered so that it will view each number independently."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MTEEbBoaGmrw","executionInfo":{"status":"ok","timestamp":1735856381346,"user_tz":480,"elapsed":81,"user":{"displayName":"Neha Bala","userId":"08158616502322850116"}}},"outputs":[],"source":["# Employ one-hot encoding on your training labels.\n","train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n","\n","# Employ one-hot encoding on your test labels.\n","test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"]},{"cell_type":"markdown","metadata":{"id":"XanzYyhqIceK"},"source":["# Building the Network\n","Neural networks learn to accomplish their tasks by reading training data and adjusting their neuron weights to improve their chance of choosing the correct answer.\n","\n","The first network you'll create is a **densely connected network**.\n","\n","A **densely connected network** has layers of connected neurons, where the output of one layer becomes the input for the next one.\n","\n","These layers manipulate and reshape the data so that the computer can guess what the output should be."]},{"cell_type":"markdown","metadata":{"id":"_4eeuJgwIm94"},"source":["## Import Model and Layers\n","You'll use a framework called TensorFlow to build, compile, and run your first neural network that can detect handwritten digits. To get started, you'll import the Sequential model and Dense and Flatten layers to perform calculations on the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLsacdUqIhio"},"outputs":[],"source":["# Import the Sequential model.\n","\n","\n","# Import the Dense and Flatten layers.\n"]},{"cell_type":"markdown","metadata":{"id":"M3_FRvX5IzWU"},"source":["## Epochs and Model Layers\n","Next, you'll setup the epochs, create a new model, and add the input, hidden, and output layers. Finally, you'll print the summary of your network so far.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRWFzpeGJBEk"},"outputs":[],"source":["# Create a variable called epochs and set the value as 10.\n","\n","\n","# Create a new model object using the Keras Sequential.\n","\n","\n","# Add a Flatten layer and pass the input shape as an argument.\n","\n","\n","# Add a Dense layer to your network with the size of the layers in neurons and relu as the activation function.\n","\n","\n","# Add an output layer.\n","\n","\n","# Print a summary of your network so far.\n"]},{"cell_type":"markdown","metadata":{"id":"ldmLMHqRLFbE"},"source":["# Training the Network\n","Now, it's time to compile the network! TensorFlow has a command that will do a lot of the work for you, but you still need to set up a few arguments so that this network is compiled effectively.\n","\n","You'll add this line to compile your network, and then read below to learn more about each argument."]},{"cell_type":"markdown","metadata":{"id":"bQwwYekXLLRh"},"source":["## Compile the Network\n","By compiling the network, your model output will decide what class an image belongs to. The optimizer will be a general-purpose algorithm called Adam. The Adam algorithm will help the neural network adjust the weights to learn based on the incorrect calculations it makes.\n","\n","The loss algorithm is categorical cross-entropy. The cross-entrophy algorithm matches the network's predictions to the actual results to test for accuracy. Since this problem involves sorting data into categories, the metric to watch is accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75V8MJfbLJ5N"},"outputs":[],"source":["# Add the compile function that calculates the loss and uses the optimizer parameter to set the optimization algorithm.\n"]},{"cell_type":"markdown","metadata":{"id":"ichoNcbPLvNi"},"source":["## Training\n","Now that you have a compiled model, you can fit that model to the actual data that you prepared. The fit stage will use the training data to train the model to recognize numbers.\n","\n","The **train_images** data set will be the input. The **train_labels** will track whether the network guess is correct, and the **epochs** will equal the variable you set up earlier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5i4WUsFLwIy"},"outputs":[],"source":["# Add the fit function and set the input data for the model so the network doesn't rely on a pattern to learn.\n"]},{"cell_type":"markdown","metadata":{"id":"RtCk_-PUL3j8"},"source":["## Analyzing the Output\n","Knowing how well the model did on the training data could be more helpful. It means little if you get an A on a test where you're given the answers.\n","\n","The real test of a model is how well it does on data it has yet to see before and doesn't know the labels for. That's exactly what the **model.evaluate()** function is for.\n","\n","This function takes the trained model and the test data and produces a set of scores, or metrics, that show how well the model did on this test data.\n","\n","While **model.evaluate()** takes the test labels as input, they're never shown to the neural network, only used to compare the network's answer to the real answer.\n","\n","After evaluation, this function's final point is to return the model object for use later, as needed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QlE5OzyL4YA"},"outputs":[],"source":["# Calculate the loss and accuracy of your model.\n","\n","\n","# Print out the test accuracy.\n"]},{"cell_type":"markdown","metadata":{"id":"QzCJjntCwgkj"},"source":["For each epoch, you can see the network's loss and accuracy on the training data. As you can see, the accuracy increases with each epoch, and the loss decreases.\n","\n","Finally, the test accuracy tells you how accurate the network was with the test data.\n","\n","This model should be about 95% accurate on the test data for this particular run. That's pretty good!"]},{"cell_type":"markdown","metadata":{"id":"ZN-OucAVMOxG"},"source":["## Exporting the Model\n","\n","Finally, now that you have a finished model, you can export it. Follow these steps to download a copy of your network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2egXOIbgMQBC"},"outputs":[],"source":["# Export your model\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}